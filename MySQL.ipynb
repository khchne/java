{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 数据库三范式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **第一范式**：**所有属性不可再分**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **第二范式**：**所有非主属性完全依赖于主属性集**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **第三范式：**所有非主属性**不传递依赖于主属性**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**不符合范式会出现哪些异常？**\n",
    "* 冗余数据：某些同样的数据多次出现（如学生姓名）；\n",
    "* 修改异常：修改了一个记录中的信息，另一个记录中相同的信息却没有修改；\n",
    "* 删除异常：删除一个信息，那么也会丢失其它信息（删除一个课程，丢失了一个学生的信息）；\n",
    "* 插入异常：无法插入（插入一个还没有课程信息的学生）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 事务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "事务是一个操作序列集，是一个不可分割的工作单位，以begin transaction开始，以commit/rollback结束"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**事务的特性：ACID**\n",
    "* A 原子性：逻辑上是不可分割的操作单元，事务的所有操作要么全部提交成功，要么全部失败回滚（用回滚日志实现，反向执行日志中的操作）；\n",
    "* C 一致性：应用系统从一个正确的状态到另一个正确的状态；系统**从一个正确的状态,迁移到另一个正确的状态**.什么叫正确的状态呢?就是当前的状态满足预定的约束就叫做正确的状态\n",
    "* I 隔离性：一个事务所做的修改在最终提交以前，对其它事务是不可见的（并发执行的事务之间不能相互影响）；\n",
    "* D 持久性：一旦事务提交成功，对数据的修改是永久性的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MySQL是如何实现事务的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://blog.csdn.net/Baisitao_/article/details/104723795"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**原子性是通过 undo log来实现的 （因为undo log记载着数据修改前的信息/ 记录了一条相反的信息）**  \n",
    "\n",
    "**undo log**主要存储的也是逻辑日志，比如我们要insert一条数据了，那undo log会记录的一条对应的delete日志。我们要update一条记录时，它会记录一条对应**相反的**update记录。\n",
    "\n",
    "这也应该容易理解，毕竟回滚嘛，跟需要修改的操作相反就好，这样就能达到回滚的目的。因为支持回滚操作，所以我们就能保证：“一个事务包含多个操作，这些操作要么全部执行，要么全都不执行”。【原子性】"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**持久性是通过 redo log来实现的**  \n",
    "redo log叫做重做日志，是用来实现事务的持久性。该日志文件由两部分组成：重做日志缓冲（**redo log buffer**）以及重做日志文件（redo log）,前者是在**内存**中，后者在**磁盘**中。当**事务提交之后**会把所有修改信息都会存到该日志中。\n",
    "\n",
    "如果中途MySQL宕机了，可以通过加载redo log来对数据进行恢复"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**redo log**  \n",
    "* redo log写入磁盘的时候，是用 **顺序IO**，所以写入很快\n",
    "* redo log记载的是物理变化（xxxx页做了xxx修改），文件的体积很小，恢复速度很快。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2. MySQL中的几种日志\n",
    "\n",
    "* binlog\n",
    "* undo log\n",
    "* redo log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://juejin.cn/post/6860252224930070536#comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### binlog\n",
    "\n",
    "* 用于记录数据库执行的**写入性操作**(不包括查询)信息，以**二进制**的形式保存在磁盘中。binlog是mysql的**逻辑日志**，并且由**Server层**进行记录，使用**任何**存储引擎的mysql数据库都会记录binlog日志。\n",
    "* binlog是通过追加的方式进行写入的，可以通过max_binlog_size参数设置每个binlog文件的大小，当文件大小达到给定值之后，会生成新的文件来保存日志。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**逻辑日志：可以简单理解为记录的就是sql语句。**\n",
    "\n",
    "**物理日志：因为mysql数据最终是保存在数据页中的，物理日志记录的就是数据页变更**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**binlog刷盘时机**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由参数**sync_binlog**控制\n",
    "\n",
    "* 当sync_binlog为0时，表示MySQL不控制binlog的刷新，而是由系统自行判断何时写入磁盘。选这种策略，一旦操作系统宕机，缓存中的binlog就会丢失。\n",
    "* sync_binlog为N时，每N个事务，才会将binlog写入磁盘。。\n",
    "* 当sync_binlog为1时，则表示每次commit，都将binlog 写入磁盘\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般情况下是，先把修改日志写到缓存中的binlog,再等合适的时机，写入磁盘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/binlog.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### redo log——持久性\n",
    "\n",
    "* 只记录事务对数据页做了哪些修改\n",
    "* 它指事务中修改了的数据，将会备份存储。\n",
    "* 发生数据库服务器宕机、或者脏页未写入磁盘，可以通过redo log恢复。\n",
    "* **Innodb存储引擎独有的**\n",
    "* redo log的大小是固定。它采用**循环写**的方式记录，当写到结尾时，会回到开头循环写日志"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "redo log包括两部分：一个是内存中的**日志缓冲(redo log buffer)**，另一个是磁盘上的**日志文件(redo log file)** 。mysql每执行一条DML语句，先将记录写入redo log buffer，后续某个时间点再一次性将多个操作记录写到redo log file。这种**先写日志，再写磁盘**的技术就是MySQL里经常说到的**WAL(Write-Ahead Logging) 技术。**\n",
    "\n",
    "**WAL的好处**：不用每一次操作都实时把数据写盘，就算crash后也可以通过redo log恢复，所以能够实现快速响应SQL语句  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**redo log刷盘**  \n",
    "因为用户空间中的缓存是无法直接写到硬盘中去的，需要经过内核空间的缓冲区；SO  \n",
    "* 日志最开始会写入位于存储引擎Innodb的redo log buffer，这个是在用户空间完成的。\n",
    "* 然后再将日志保存到操作系统内核空间的缓冲区(OS buffer)中。\n",
    "* 最后，通过系统调用fsync()，从OS buffer写入到磁盘上的redo log file中，完成写入操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/redolog.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/crash-redolog.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### undo log——原子性"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 用于记录数据被修改前的信息。\n",
    "* undo log主要记录了数据的逻辑变化，比如一条INSERT语句，对应一条DELETE的undo log，对于每个UPDATE语句，对应一条相反的UPDATE的undo log，这样在发生错误时，就能回滚到事务之前的数据状态"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-3事务的两阶段提交"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "两阶段提交的过程：  \n",
    "1. redo log在写入后，进入prepare状态\n",
    "2. 执行器写入bin log\n",
    "3. 进入commit状态，事务可以提交。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**为什么要两阶段提交事务**  \n",
    "\n",
    "* 保证数据一致性\n",
    "* 如果不用两阶段提交的话，可能会出现这样情况：bin log写入之前，机器crash导致需要重启。重启后redo log继续重放crash之前的操作，而当bin log后续需要作为备份恢复时，会出现数据不一致的情况。\n",
    "\n",
    "\n",
    "* 如果是bin log commit之前crash，那么重启后，发现redo log是prepare状态且bin log完整（bin log写入成功后，redo log会有bin log的标记），就会自动commit，让存储引擎提交事务。\n",
    "\n",
    "\n",
    "* 两阶段提交就是为了保证redo log和binlog数据的安全一致性。只有在这两个日志文件逻辑上高度一致了。你才能放心的使用redo log帮你将数据库中的状态恢复成crash之前的状态，使用binlog实现数据备份、恢复、以及主从复制。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/transction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 语句"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一条SQL查询语句是如何执行的？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sql\n",
    "select * from T where ID=10;\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 连接数据库\n",
    "2. 查询缓存（8.0以后被淘汰）  \n",
    "    在缓存中查看这条SQL语句是否曾经执行过，之前执行过的SQL语句会以key-value的形式缓存下来，其中key就是语句本身，value是执行的结果\n",
    "    由于只要表更新，缓存即失效，不建议用缓存查询\n",
    "    \n",
    "    \n",
    "3. 解析SQL语句（分析器）  \n",
    "    分析器首先先做 **语法解析**，识别关键字并判断这条SQL语句是否符合MySQL的语法，如果语法错误，则报错退出\n",
    "    \n",
    "    \n",
    "4. 优化处理 （优化器）  \n",
    "    优化器决定选择什么样的索引，怎样的表连接顺序等\n",
    "    \n",
    "    \n",
    "5. 执行语句 （执行器）\n",
    "    \n",
    "    先判断有没有对这个表执行查询 的权限，如果没有，则返回 无权限错误  \n",
    "    如果有权限则  \n",
    "    调用存储引擎提供的接口，逐行执行语句，并将  \n",
    "    遍历过程中所有满足条件的 行组 作为结果集返回给客户端  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/mysql-select.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count(1)和count(*)差别，哪个快 （InnoDB存储引擎）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在无条件的查询中  \n",
    "* MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(\\*) 的时候会**直接返回这个数，效率很高**；\n",
    "* 而 InnoDB 引擎就麻烦了，它执行 count(\\*) 的时候，需要**把数据一行一行**地从引擎里面读出来，然后累积计数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照效率排序的话，count(字段)<count(主键id)<count(1) 约等于 count(\\*)。因为mysql对count(\\*)有优化，认为是取行数，不需要把字段取出来"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 隔离级别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **未提交读**（Read Uncommited）：在一个事务提交之前，它的执行结果对其它事务也是可见的。会导致脏读、不可重复读、幻读；\n",
    "* **提交读**（Read Commited）：一个事务只能看见已经提交的事务所作的改变。可避免脏读问题；\n",
    "* **可重复读**（Repeatable Read）：可以确保同一个事务在多次读取同样的数据时得到相同的结果。（**MySQL的默认隔离级别**）。可避免不可重复读；\n",
    "* **可串行化**（Serializable）：强制事务串行执行，使之不可能相互冲突，从而解决幻读问题。可能导致大量的超时现象和锁竞争，实际很少使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**实现原理——通过 锁&MVCC实现**\n",
    "* **未提交读（RU）**：读不加锁，写加行锁\n",
    "* **提交读（RC）**：MVCC\n",
    "* **可重复读（RR)**: MVCC\n",
    "* **串行化读**: 读写都加锁，读加共享锁，写加排他锁，读写互斥\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 存储引擎"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **InnoDB:** MySQL默认的存储引擎  \n",
    "    - 每个 InnoDB 表在数据库目录中以.frm 格式文件表示  \n",
    "    - InnoDB 表空间 tablespace 被用于存储表的内容  \n",
    "    - 提供一组用来记录事务性活动的日志文件  \n",
    "    - 用 COMMIT(提交)、 SAVEPOINT 及 ROLLBACK(回滚)支持事务处理  \n",
    "    - 提供全 ACID 兼容  \n",
    "    - 在 MySQL 服务器崩溃后提供自动恢复  \n",
    "    - 多版本（ MVCC）和行级锁定  \n",
    "    - 支持外键及引用的完整性，包括级联删除和更新  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **MyISAM:**  拥有较高的插入、查询速度，但不支持事物和外键。   \n",
    "    * 可被转换为压缩、只读表来节省空间\n",
    "    * 使用三个文件表示每个表：  \n",
    "    • 格式文件 — 存储表结构的定义（ mytable.frm）  \n",
    "    • 数据文件 — 存储表行的内容（ mytable.MYD）  \n",
    "    • 索引文件 — 存储表上索引（ mytable.MYI）  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **MEMORY:** 数据存储在内存中，为查询和引用其他表数据提供快速访问   \n",
    "    * MEMORY表使用一个固定的记录长度格式\n",
    "    * 表数据及索引被存储在内存中\n",
    "    * 表级锁机制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MySQL的两种存储引擎 InnoDB 和 MyISAM 的区别？**\n",
    "* InnoDB **支持事务**，可以进行Commit和Rollback；\n",
    "* MyISAM 只支持表级锁，而 InnoDB 还**支持行级锁**，提高了并发操作的性能；\n",
    "* InnoDB **支持外键**；\n",
    "* MyISAM **崩溃**后发生损坏的概率比 InnoDB 高很多，而且**恢复的速度**也更慢；\n",
    "* MyISAM 支持**压缩**表和空间数据索引，InnoDB需要更多的内存和存储；\n",
    "* InnoDB 支持在线**热备份**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 索引"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. 什么是索引**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 索引其实是一种数据结构，能够帮助我们快速的检索数据库中的数据；在MySQL中默认使用的是InnoDB存储引擎，用的是B+树索引  \n",
    "* 任何标准表最多可以创建**16个索引列**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.2 为什么要建立索引， 索引的优缺点**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建索引可以大大提高系统的性能  \n",
    "**优点：**  \n",
    "\n",
    "\n",
    "     第一、通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。   \n",
    "     第二、可以大大加快 数据的检索速度，这也是创建索引的最主要的原因。   \n",
    "     第三、可以加速表和表之间的连接，特别是在实现数据的参考完整性方面特别有意义。   \n",
    "     第四、在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间。   \n",
    "     第五、通过使用索引，可以在查询的过程中，使用优化隐藏器，提高系统的性能。  \n",
    "        \n",
    " **缺点：**  \n",
    " \n",
    "     第一、创建索引和维护索引要耗费时间，这种时间随着数据量的增加而增加。 \n",
    "\n",
    "     第二、索引需要占物理空间，除了数据表占数据空间之外，每一个索引还要占一定的物理空间。如果要建立聚簇索引，那么需要的空间就会更大。 \n",
    "\n",
    "     第三、当对表中的数据进行增加、删除和修改的时候，索引也要动态的维护，这样就降低了数据的维护速度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**索引建立的原则**  \n",
    "1. 在经常需要**搜索/查询/排序**的列创建索引\n",
    "2. 在作为**主键的列上**，强制该列的唯一性和组织表中数据的排列结构；\n",
    "3. 在经常用在**连接的列上**，这些列主要是一些外键，可以加快连接的速度；\n",
    "4. 在经常使用在**WHERE子句**中的列上面创建索引，加快条件的判断速度。   \n",
    "而对于以下字段，不宜建立索引    \n",
    "1. 查询/搜索/排序用的少的字段\n",
    "2. text img bit数据类型的字段不宜建立索引，因为数据量太大了\n",
    "3. 修改远大于查询的字段不宜建立索引；因为修改数据会导致索引失效，需要重新维护索引，非常消耗性能"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.3 索引的数据结构还有哪些**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* hash\n",
    "* B+ tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.4 B+ Tree索引和Hash索引区别**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hash索引的特点：  \n",
    "* 基于哈希表，kv结构\n",
    "* 数据存储上是无序的\n",
    "* 单次等值查询只要O(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**区别：**  \n",
    "1. Hash索引适合等值查询，不适合范围查询；在范围查询时，hash索引需要全表查询\n",
    "2. Hash索引无法利用索引完成排序；B+ Tree是天然有序的\n",
    "3. 哈希索引不支持多列联合索引的**最左前缀匹配规则**\n",
    "4. 如果有大量重复键值的情况下，哈希索引的效率会很低，因为存在哈希碰撞问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.5 索引失效**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 以“%”开头的LIKE语句，模糊匹配\n",
    "\n",
    "2. OR语句前后没有同时使用索引\n",
    "\n",
    "3. 数据类型出现隐式转化（如varchar不加单引号的话可能会自动转换为int型）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.6 索引分类与特点**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从**功能逻辑**上分，有4种：普通索引、唯一索引、主键索引和全文索引\n",
    "\n",
    "* **普通索引**是基础的索引，没有任何约束，主要用于提高查询效率。  \n",
    "\n",
    "* **唯一索引**就是在普通索引的基础上增加了数据**唯一性**的约束，在一张数据表里**可以有多个唯一索引**。  \n",
    "\n",
    "* **主键索引**在**唯一索引的基础上**增加了不为空的约束(**非空约束**)，也就是 NOT NULL+UNIQUE，一张表里最多**只有一个**主键索引（因为数据存储在文件中只能按照一种顺序进行存储）  \n",
    "\n",
    "* **全文索引**用的不多，MySQL 自带的全文索引只支持英文。我们通常可以采用专门的全文搜索引擎，比如 ES(ElasticSearch) 和 Solr。  \n",
    "\n",
    "\n",
    "从**物理实现**方式分，有2类：聚集索引和非聚集索引。我们也把非聚集索引称为二级索引或者辅助索引。  \n",
    "\n",
    "* **聚集索引**：是一种数据的存储方式，它的行数据是直接存放在索引的叶子页中的。 \n",
    "\n",
    "* **非聚集索引**：用来构建索引的字段会存储在叶子节点，然后叶子节点中所保存的“行指针”，实际上存储的是**主键值**，也就是说，非聚集索引，维护的是一个 索引列 + 主键列的数据（也就是主键值）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 聚集索引和非聚集索引二者的区别\n",
    "\n",
    "1. 聚集索引的叶子节点存储的就是我们的数据记录，非聚集索引的叶子节点存储的是数据位置。非聚集索引不会影响数据表的物理存储顺序。\n",
    "2. 一个表只能有一个聚集索引，因为只能有一种排序存储的方式，但可以有多个非聚集索引，也就是多个索引目录提供数据检索。\n",
    "3. 使用聚集索引的时候，数据的**查询**效率高，但如果对数据进行**插入，删除，更新**等操作，效率会比非聚集索引低。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 如何评价索引的数据结构设计好坏？\n",
    "* 虽然内存的读取速度很快，但我们还是需要将索引存放到硬盘上。因此，当我们在硬盘上进行查询时，也就产生了硬盘的 I/O 操作。\n",
    "* 我们都知道，硬盘的 I/O 存取消耗的时间相比于内存的存取来说，要高很多。我们通过索引来查找某行数据的时候，需要计算产生的磁盘 I/O 次数，当磁盘 I/O 次数越多，所消耗的时间也就越大。\n",
    "* 如果我们能让索引的数据结构尽量**减少硬盘的 I/O 操作**，所消耗的时间也就越小，那么这个索引的数据结构设计的也就越优。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ICP的限制**  \n",
    "1. ICP 仅用于需要访问基表所有记录时使用，适用的访问方法为：range、ref、eq_ref、ref_or_null。（ICP 尤其是对联合索引的部分列模糊查找非常有效。）  \n",
    "\n",
    "2. ICP 同样适用于分区表。  \n",
    "\n",
    "3. ICP 的目标是减少全行记录读取，从而减少 I/O 操作，仅用于二级索引。**主键索引本身即是表数据，不存在下推操作。**  \n",
    "\n",
    "4. ICP 不支持基于虚拟列上建立的索引，比如函数索引。  \n",
    "\n",
    "5. ICP 不支持引用子查询的条件。  \n",
    "  \n",
    "6. 引用了存储函数的条件不能下推，因为存储引擎无法调用存储函数。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.8 回表  \n",
    "回表指的是 当前索引无法检索出需要查询的所有内容，需要通过主键进行二次查询  \n",
    "也就是说： 在查询时，是先通过 一个索引字段，找到 聚集索引的字段（如主键），然后再通过聚集索引 （主键）二次查询，得出数据。  \n",
    "当然不是什么时候用 非聚集索引都会 产生回表的，只有 当前索引 无法 检索出需要查询的所有内容时，才会 进行回表查询，如果通过当前 索引，可以检索出全部数据，不会回表"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 锁 （封锁类型）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "行锁，表锁，页级锁，意向锁，读锁，写锁，悲观锁，乐观锁，以及加锁的sql语句\n",
    "\n",
    "\n",
    "* **排它锁**（Exclusive Lock）/ X锁 / 写锁：事务对数据加上X锁时，只允许此事务读取和修改此数据，并且其它事务不能对该数据加任何锁；\n",
    "* **共享锁**（Shared Lock）/ S锁 / 读锁：加了S锁后，该事务只能对数据进行读取而不能修改，并且其它事务只能加S锁，不能加X锁\n",
    "* **意向锁**（Intention Locks）：\n",
    "    * **意向锁是 InnoDB 自动加的， 不需用户干预**\n",
    "    * 一个事务在获得某个数据行对象的 S 锁之前，必须先获得**整个表**的 IS 锁或更强的锁；\n",
    "    * 一个事务在获得某个数据行对象的 X 锁之前，必须先获得整个表的 IX 锁；\n",
    "    * **IS/IX 锁之间都是兼容的；**意向锁之间不会冲突, 因为意向锁只是代表要对某行记录进行操作  \n",
    "    * **好处：**如果一个事务想要对整个表加X锁，就需要先检测是否有其它事务对该表或者该表中的某一行加了锁，这种检测非常耗时。有了意向锁之后，只需要检测整个表是否存在IX/IS/X/S锁就行了\n",
    "    * **意向锁的意义在于方便检测表锁和行锁之间的冲突**\n",
    "    \n",
    "**没有意向锁的情况，需要加 锁：**  \n",
    "1、判断表是否已被其他事务用表锁锁表。  \n",
    "2、判断表中的每一行是否已被行锁锁住，这样要**遍历整个表**，效率很低。  \n",
    "**意向锁存在的情况：**  \n",
    "1、判断表是否已被其他事务用表锁锁表。  \n",
    "2、判断表上是否有意向锁"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MyISAM仅支持表锁**  \n",
    "**特点：** 开销小；加锁快；粒度大，并发性能低；无死锁情况；   \n",
    "所以：  \n",
    "1. 读锁会阻塞写操作，不会阻塞读操作\n",
    "2. 写锁会阻塞读和写操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**InnoDB支持行锁**，InnoDB行锁是通过给索引上的索引项加锁来实现的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **表级锁：**开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低。数据库引擎总是**一次性**同时获取所有需要的锁以及总是按相同的顺序获取表锁从而避免死锁。\n",
    "* **行级锁：**开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。行锁总是**逐步**获得的，因此会出现死锁。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/mysql-lock.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. SQL性能优化\n",
    "\n",
    "explain、慢查询日志"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 分库分表\n",
    "\n",
    "（水平切分、垂直切分）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**为什么为分库分表（sharding）**\n",
    "* 数据量大，查询慢，性能差，安全系数不高，连接数有限"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 垂直切分——垂直分库，垂直分表\n",
    "\n",
    "* 垂直分库：按照业务分类进行划分，每个业务有独立数据库\n",
    "* 垂直分表：就是字段的切分，可以按照字段的访问频率，把经常访问的字段和不常访问的字段切分；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**优点：**\n",
    "\n",
    "* 业务间解耦，不同业务的数据进行独立的维护、监控、扩展\n",
    "* 在高并发场景下，一定程度上缓解了数据库的压力\n",
    "\n",
    "\n",
    "\n",
    "**缺点：**\n",
    "\n",
    "* 提升了开发的复杂度，由于业务的隔离性，很多表无法直接访问，必须通过接口方式聚合数据，\n",
    "* 分布式事务管理难度增加\n",
    "* 数据库还是存在单表数据量过大的问题\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 水平切分——库内分表，分库分表（水平分库）\n",
    "* 库内分表：将一个表中的数据分散到同一个库中的几个表\n",
    "* 分库分表：将一个表切分出的子表分到不同的库中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**优点：**\n",
    "\n",
    "* 解决高并发时单库数据量过大的问题，提升系统稳定性和负载能力\n",
    "* 业务系统改造的工作量不是很大\n",
    "\n",
    "**缺点：**\n",
    "\n",
    "* 跨分片的事务一致性难以保证\n",
    "* 跨库的join关联查询性能较差\n",
    "* 扩容的难度和维护量较大"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分库分表的策略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **按照取值范围分**：按照时间或者ID序号或者可以排序的东西，按照一定的区间分成若干个库  \n",
    "\n",
    "**优点：**\n",
    "\n",
    "* 单表数据量是可控的\n",
    "* 水平扩展简单只需增加节点即可，无需对其他分片的数据进行迁移\n",
    "* 能快速定位要查询的数据在哪个库  \n",
    "\n",
    "\n",
    "\n",
    "**缺点：**\n",
    "\n",
    "* 由于连续分片可能存在数据热点，如果按时间字段分片，有些分片存储最近时间段内的数据，可能会被频繁的读写，而有些分片存储的历史数据，则很少被查询\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **hash取模：**有相同哈希值的数据存放在同一个库中  \n",
    "\n",
    "**优点：**\n",
    "\n",
    "* 数据分片相对比较均匀，不易出现某个库并发访问的问题\n",
    "\n",
    "\n",
    "\n",
    "**缺点：**\n",
    "\n",
    "* 但这种算法存在一些问题，当某一台机器宕机，本应该落在该数据库的请求就无法得到正确的处理，这时宕掉的实例会被踢出集群，此时算法变成hash(userId) mod N-1，用户信息可能就不再在同一个库中。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 分库分表的数据迁移\n",
    "\n",
    "1. 一旦分表上线后所有的数据写入、查询都是针对于分表的，所以原有大表内的数据必须得迁移到分表里，不然对业务的影响极大。\n",
    "2. 我们估算了对一张 2 亿左右的表进行迁移，自己写的迁移程序，大概需要花 4~5 天的时间才能完成迁移。\n",
    "3. 意味着这段时间内，以前的数据对用户是不可见的，显然这样业务不能接受。\n",
    "4. 于是我们做了一个兼容处理：分表改造上线后，所有新产生的数据写入分表，但对历史数据的操作还走老表，这样就少了数据迁移这一步骤。\n",
    "5. 只是需要在操作数据之前做一次路由判断，当新数据产生的足够多时（我们是两个月时间），几乎所有的操作都是针对于分表，再从库启动数据迁移，数据迁移完毕后将原有的路由判断去掉。\n",
    "6. 最后所有的数据都从分表产生和写入。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. MySQL主从复制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **原理**\n",
    " \n",
    "**主节点** \n",
    "1. 当主节点上进行 insert、update、delete 操作时，会按照时间先后顺序写入到 binlog 中；\n",
    "\n",
    "\n",
    "2. 当从节点连接到主节点时，主节点会创建一个叫做 binlog dump 的线程；\n",
    "\n",
    "\n",
    "3. 一个主节点有多少个从节点，就会创建多少个 binlog dump 线程；\n",
    "\n",
    "\n",
    "4. 当主节点的 binlog 发生变化的时候，也就是进行了更改操作，binlog dump 线程就会通知从节点 (Push模式)，并将相应的 binlog 内容发送给从节点；\n",
    "\n",
    "\n",
    "**从节点**\n",
    "\n",
    "\n",
    "当开启主从同步的时候，从节点会创建两个线程用来完成数据同步的工作。\n",
    "\n",
    "\n",
    "1. **I/O线程**： 此线程连接到主节点，主节点上的 binlog dump 线程会将 binlog 的内容发送给此线程。此线程接收到 binlog 内容后，再将内容写入到本地的 relay log。\n",
    "2. **SQL线程**： 该线程读取 I/O 线程写入的 relay log，并且根据 relay log 的内容对从数据库做对应的操作。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/ms.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**主从同步的方式**\n",
    "1. **同步复制**：当主库执行完一个事务，然后**所有的从库**都复制了该事务并成功执行完才返回成功信息给客户端\n",
    "\n",
    "\n",
    "2. **半同步复制**：在异步复制的基础上，确保任何一个主库上的事物在提交之前至少有一个从库已经收到该事物并日志记录下来\n",
    "\n",
    "\n",
    "3. **延迟复制**：在异步复制的基础上，人为设定主库和从库的数据同步延迟时间\n",
    "\n",
    "\n",
    "4. **异步复制**：主节点不会主动推送数据到从节点，主库在执行完客户端提交的事务后会**立即**将结果返给给客户端，并不关心从库是否已经接收并处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. MVCC多版本并发控制\n",
    "\n",
    "https://juejin.cn/post/7020422614552150052#heading-0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* MVCC是一种通过增加版本冗余数据来实现并发控制的方法，一般在数据库管理系统中，实现对数据库的并发访问，在编程语言中实现事务内存。\n",
    "* MVCC是被Mysql中事务型存储引擎**InnoDB**所支持的;\n",
    "* 应对高并发事务, MVCC比单纯的加行锁更有效, 开销更小;\n",
    "* MVCC只在 **READ COMMITTED(RC)** 和 **REPEATABLE READ(RR)** 两个隔离级别下工作;\n",
    "* MVCC就是由 **undo log多版本链 + ReadView** 构成的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在InnoDB所支持的库/表中，会有3个额外的字段：  \n",
    "* DB_TRX_ID：6-byte的**事务ID**。插入或更新行的最后一个事务的事务ID，也就是当前事务的ID\n",
    "* DB_ROLL_PTR：7-byte的**回滚指针**。就是指向对应某行记录的上一个版本，在undo log中使用。\n",
    "* DB_ROW_ID：6-byte的**隐藏主键**。如果数据表中没有主键，那么InnoDB会自动生成单调递增的隐藏主键（表中有主键或者非NULL的UNIQUE键时都不会包含 DB_ROW_ID列）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/versionLink.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ReadView"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ReadView 是事务快照读的时候产生的数据读**视图**，在该事务执行快照读的那一刻，会生成一个数据系统当前的快照，记录并维护系统当前活跃事务的id，**事务的id值是递增的**。\n",
    "\n",
    "\n",
    "* ReadView 的最大作用就是**判断数据的可见性**，当某个事务执行快照读的时候，会对此记录创建一个ReadView 的视图，在整个事务期间根据某些条件判断该事务能够看到的版本链上的哪条历史数据。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**四个全局属性**  \n",
    "\n",
    "* **m_ids**：表示在生成ReadView 时当前系统中活跃事务的事务id列表。\n",
    "* **m_low_limit_id**：表示在生成ReadView 时当前系统应该分配给下一个事务的事务id(也就是还未分配的事务id 即**最大事务id+1**)\n",
    "* **m_up_limit_id**：表示在生成 ReadView 时当前系统中活跃的读写事务中**最小的 事务id** ，也就是 m_ids 中的最小值。\n",
    "* **m_creator_trx_id**：表示生成该 ReadView 的事务的 事务id，**当前事务ID**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**判断是否可见**  \n",
    "1. 如果被访问记录的版本事务ID与ReadView 中的m_creator_trx_id值相同，那么表示当前事务访问的是自己修改过的记录，那么该版本对当前事务可见；\n",
    "\n",
    "\n",
    "2. 如果被访问版本的 事务ID小于 ReadView 中的m_up_limit_id的值，那么表示生成该版本的事务在当前事务生成 ReadView 前已经提交，所以该版本可以被当前事务访问。\n",
    "\n",
    "\n",
    "3. 如果被访问版本的事务ID大于 ReadView 中的m_low_limit_id 值，那么表示生成该版本的事务在当前事务生成 ReadView 后才开启，所以该版本不可以被当前事务访问。\n",
    "\n",
    "\n",
    "4. 如果被访问版本的 事务ID在 ReadView 的m_up_limit_id和m_low_limit_id 之间，那就需要判断一下版本的事务ID是不是在 m_ids 列表中，如果在，说明创建 ReadView 时生成该版本的事务还是活跃的，该版本不可以被访问；如果不在，说明创建 ReadView 时生成该版本的事务已经被提交，该版本可以被访问。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "简单而言，就是，\n",
    "* 如果被访问版本的 事务ID <= 当前记录的最小ID，或者等于当前ID，或者在最大和最小ID之间且不在活跃列表中，则这个版本的数据中可见的；  \n",
    "* 如果被访问版本的 事务ID >= 当前记录最大ID，或者在活跃列表中的，则不可见"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RR和RC下快照读为什么不同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 因为二者生成ReadView的时机不同"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RR：事务的对某条记录的**第一次快照读会创建ReadView**,生成的时候ReadView中就记录了其四个属性，包括活跃事务列表，此后在调用快照读的时候，还是使用的是同一个ReadView，不会重新生成\n",
    "\n",
    "* RC：事务中，**每次快照读都会新生成一个快照和ReadView**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
