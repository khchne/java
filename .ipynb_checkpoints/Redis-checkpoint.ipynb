{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Redis事务"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "事务执行的方式：在一个事务中执行所有先前放入队列的命令，然后恢复正常的连接状态。  \n",
    "\n",
    "<li>如果在把命令压入队列的过程中报错， 则整个队列中的命令都不会执行，执行结果报错；</li>\n",
    "<li>如果在压队列的过程中正常，在执行队列中某一个命令报错，则只会影响本条命令的执行结果， 其它命令正\n",
    "常运行；</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 开始事务（MULTI）\n",
    "2. 命令入队\n",
    "3. 执行事务（EXEC）、撤销事务（DISCARD ）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Redis数据类型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**对于Redis的key和value,一般而言，key都是String,而value有以下5个常用类型，且value都是以对象的形式存在的**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c++\n",
    "typedef struct redisObject {\n",
    "    unsigned [type] 4;\n",
    "    unsigned [encoding] 4;\n",
    "    unsigned [lru] REDIS_LRU_BITS;\n",
    "    int refcount;\n",
    "    void *ptr;\n",
    "} robj;\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* type：数据类型，就是我们熟悉的string、hash、list等。\n",
    "* encoding：内部编码，不同的编码方式，会对应不同的底层数据结构实现；\n",
    "* REDIS_LRU_BITS：当前对象可以保留的时长。\n",
    "* refcount：对象引用计数，用于GC。\n",
    "* ptr：指针，指向以encoding的方式实现这个对象的实际地址。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在string中，embstr编码，对应的是：sds实现 <=39 字节；raw编码，对应的是：sds实现 > 39字节"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/kv.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**String**：2种存储结构：int 存放整数类型, SDS 存放浮点数、字符串、字节类型\n",
    "* SDS: 简单动态字符串 simple dynamic string\n",
    "* 使用一个结构体的方式，方便扩容；\n",
    "    * 当字符串的长度**小于 1MB时**，每次扩容都是**加倍**现有的空间。\n",
    "\n",
    "    * 如果字符串长度**超过 1MB时**，每次扩容时只会扩展 **1MB** 的空间。\n",
    "\n",
    "    * 这样既保证了内存空间够用，还不至于造成内存的浪费，**字符串最大长度为 512MB.**\n",
    "    \n",
    "* string采用的是**惰性空间释放**，当字符串缩短时，并没有真正的缩容，而是**移动free的指针**。这样将来字符串长度增加时，就不用重新分配内存了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c++\n",
    "typedef struct sdshdr {\n",
    "    // buf中已经占用的字符长度\n",
    "    unsigned int len;\n",
    "    // buf中剩余可用的字符长度\n",
    "    unsigned int free;\n",
    "    // 数据空间\n",
    "    char buf[];\n",
    "}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**List**：2种数据结构：linkedList & zipList(链表和压缩列表)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当list对象中的数据同时满足以下 2 点，则使用ziplist，否则使用linkedlist\n",
    "```code\n",
    "1. list对象保存的所有字符串元素的长度都小于64字节\n",
    "2. list对象保存的元素数量小于512个，\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "linkedlist是一个双向链表，由list + listNode实现\n",
    "```c++\n",
    "typedef struct list{\n",
    "    //表头节点\n",
    "    listNode *head;\n",
    "    //表尾节点\n",
    "    listNode *tail;\n",
    "    //链表所包含的节点数量\n",
    "    unsigned long len;\n",
    "    //节点值复制函数\n",
    "    void *(*dup)(void *ptr);\n",
    "    //节点值释放函数\n",
    "    void *(*free)(void *ptr);\n",
    "    //节点值对比函数\n",
    "    int (*match)(void *ptr,void *key);\n",
    "}list;\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hash**：ziplist or dict（哈希表）  \n",
    "\n",
    "同时满足以下2点用ziplist,否则用dict\n",
    "1. hash对象保存的所有字符串元素的长度都小于64字节\n",
    "2. hash对象保存的元素数量小于512个，"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Redis中解决hash冲突用的是**链表法**\n",
    "* 当需要扩容时，需要重新哈希，采用的是**渐进式hash**,当有新数据要插入时，将新数据插入新散列表中，并且从老的散列表中拿出一个数据放入到新散列表。每次插入一个数据到散列表，都重复上面的过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set** ： intset & dict(哈希表)  \n",
    "\n",
    "同时满足以下 2 点作 intset,否则用dict\n",
    "1. 所有元素都是整数\n",
    "2. 元素量小于 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Zset**：ziplist & 跳表  \n",
    "\n",
    "同时满足以下 2点用ziplist，否则用跳表\n",
    "1. 元素长度小于64\n",
    "2. 元素数量小于128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### skiplist与平衡树、哈希表的比较\n",
    "\n",
    "* skiplist和各种平衡树（如AVL、红黑树等）的元素是**有序排列**的，而哈希表不是有序的。因此，在哈希表上只能做单个key的查找，不适宜做范围查找。所谓范围查找，指的是查找那些大小在指定的两个值之间的所有节点。\n",
    "* 在做**范围查找**的时候，平衡树比skiplist操作要复杂。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在skiplist上进行范围查找就非常简单，只需要在找到小值之后，对第1层链表进行若干步的遍历就可以实现。\n",
    "* 平衡树的插入和删除操作可能引发子树的**调整**，逻辑复杂，而skiplist的插入和删除只需要修改相邻节点的指针，操作简单又快速。\n",
    "* 从内存占用上来说，skiplist比平衡树更灵活一些。一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而skiplist每个节点包含的指针数目平均为1/(1-p)，具体取决于参数p的大小。如果像Redis里的实现一样，取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势。\n",
    "* 查找单个key，skiplist和平衡树的**时间复杂度**都为O(log n)，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近O(1)，性能更高一些。所以我们平常使用的各种Map或dictionary结构，大都是基于哈希表实现的。\n",
    "* 从**算法实现难度**上来比较，skiplist比平衡树要简单得多"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述更加具体信息：https://juejin.cn/post/6844903929545932808#heading-0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Redis是单线程还是多线程的？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "单线程\n",
    "\n",
    "Redis 是跑在单线程中的，所有的操作都是按照顺序线性执行的，但是由于读写操作等待用户输入或输出都是阻塞的，所以 I/O 操作在一般情况下往往不能直接返回，这会导致某一文件的 I/O 阻塞导致整个进程无法对其它客户提供服务，而 **I/O 多路复用**解决了这个问题，这也就是为什么Redis速度这么快的一个原因。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. redis key 的设置"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "于复杂的设置，key的设置方式可以为：  \n",
    "1. 系统：基础数据系统\n",
    "2. 模块：数据字典\n",
    "3. 方法：根据数据字典类型查询\n",
    "4. 参数：字典类型  \n",
    "seckill:kill:doKill:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 什么情况下用Redis，什么情况用Mysql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**用Redis的场景：高并发，对数据读取效率要求高的； 即 缓存 和 高速读写**  \n",
    "1. 计数器 （项目中的预减库存）\n",
    "2. 定时器 （校验码过期时间）\n",
    "3. 热点数据缓存\n",
    "\n",
    "**用MySQL的场景：要求一系列的语句同时成功或失败回滚的业务；复杂的sql语句；对增加修改删除比较频繁**  \n",
    "1. 包含事务的业务\n",
    "2. 基于sql结构化查询储存，关系复杂\n",
    "3. 并发量不大的时候"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "热点数据（经常会被查询，但是不经常被修改或者删除的数据）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 热Key问题如何解决？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**什么是热key问题**  \n",
    "缓存中的某个key在某一瞬间被大量访问导致服务器承受不住，崩溃的情况"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 热key问题的解决"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **发现热Key**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 预估\n",
    "* 客户端收集\n",
    "* redis监控命令"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **处理热Key**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在主流的解决方案分两步：**监控热点key**和**处理热点key**。\n",
    "\n",
    "1、**监控热点key**\n",
    "\n",
    "推荐这几种方式：**按业务场景，预估热点key（必做）；客户端收集**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2、**处理热key**  \n",
    "* a. 使用**本地缓存**（二级缓存） 如使用HashMap的kv对存储\n",
    "    * 使用本地缓存需要注意两个问题：\n",
    "\n",
    "    * 如果对热 Key 进行本地缓存，需要防止本地缓存过大，影响系统性能；\n",
    "\n",
    "    * 需要处理本地缓存和 Redis 集群数据的一致性问题。\n",
    "* b. 通过水平扩容**增加副本数量**，将读请求的压力分担到不同副本节点上\n",
    "* c. **热 Key 备份**：将这些请求打散到不同的实例上，防止出现流量倾斜的情况，那么热 Key 问题也就不存在了\n",
    "    * 思路：给热 Key 加上前缀或者后缀，把一个热 Key 的数量变成 Redis 实例个数 N 的倍数 M，从而由访问一个 Redis Key 变成访问 N * M 个 Redis Key。 N * M 个 Redis Key 经过分片分布到不同的实例上，将访问量均摊到所有实例。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "不过具体情况还是要更具具体需求进行设计"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Redis为什么快？ 11w/s的读 81w/s的写"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 基于内存运行，性能高效；\n",
    "* 数据结构设计高效，例如String是由动态字符数组构成，zset内部的跳表；\n",
    "* 采用单线程，避免了线程的上下文切换，也避免了线程竞争产生的死锁等问题；\n",
    "* 使用I/O多路复用模型，非阻塞IO；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 什么是IO多路复用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“多路”指的是多个网络连接客户端，“复用”指的是复用同一个线程（单线程）。\n",
    "\n",
    "IO多路复用是一种同步IO模型；I/O多路复用是使用**一个线程**来检查多个socket的状态。在单个线程中通过记录跟踪每一个socket的状态来管理处理多个I/O流。只有当socket真正有读写事件时，才真正调用实际的IO读写操作。没有的时候会自动阻塞，交出CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I/O多路复用模型是利用select、poll、epoll(函数)可以同时监察多个流的I/O事件的能力，在**空闲的时候会把当前线程阻塞掉**。当有一个或多个流有I/O**事件**时，就会从阻塞态中**唤醒**，于是程序就会轮询一遍所有的流（epoll只轮询那些真正发出了事件的流）。如果有多个socket需要处理，就将这些socket对象放在队列中，文件事件分派器逐个读取队列中的socket并将其分发给不同的事件处理器进行处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/IO.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. LT和ET（水平触发和边缘触发）\n",
    "\n",
    "**水平触发(level-trggered)**  \n",
    "\n",
    "* 只要文件描述符关联的读内核缓冲区非空，有数据可以读取，就一直发出可读信号进行通知，\n",
    "* 当文件描述符关联的内核写缓冲区不满，有空间可以写入，就一直发出可写信号进行通知\n",
    "* 水平触发支持 block和no-block socket\n",
    "\n",
    "**边缘触发(edge-triggered)**\n",
    "\n",
    "* 当文件描述符关联的读内核缓冲区由空转化为非空的时候，则发出可读信号进行通知，\n",
    "* 当文件描述符关联的内核写缓冲区由满转化为不满的时候，则发出可写信号进行通知\n",
    "* 仅支持no-block socket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**对于LT**\n",
    "\n",
    "优点：编程更符合用户直觉，业务层逻辑更简单。   \n",
    "缺点：效率比ET低。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ET比LT更高效的原因在于：\n",
    "\n",
    "* ET在通知用户后，就会把fd从**就绪队列**里删除。而LT通知用户后fd还在就绪链表中，随着fd的增多，就绪链表越大。  \n",
    "\n",
    "* 下次epoll要通知用户时还需要**遍历整个**就绪链表。遍历的性能是线性，如果fd的数量非常多，就会带来比较显著的效率下降。  \n",
    "\n",
    "* 同样数量的fd下，LT模式维护的就绪链表比ET的大。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. select poll epoll的特点及其区别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### select特点  \n",
    "\n",
    "0. 采用的是**bitmap**数据结构存储\n",
    "1. 监听接口有限制，x64 是2048 x86 是1024\n",
    "2. 对socket采用线性扫描，时间复杂度是O(n)\n",
    "3. 需要维护一个用来存放大量fd的数据结构，且将bitmap从用户态拷贝到内核态需要一定的开销\n",
    "4. 仅支持 LT模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### poll  \n",
    "\n",
    "poll 和 select 没有本质的区别，同样是需要将数组 从用户态拷贝到内核态\n",
    "* 采用的是 **数组** 存储\n",
    "* LT模式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### epoll  \n",
    "\n",
    "1. 内核和用户空间共享一块内存\n",
    "2. 需要处理的消息的fd在就绪队列中，O(1)时间复杂度即可取得\n",
    "3. 只有活跃可用的FD才会调用callback函数；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. 缓存穿透，缓存雪崩以及缓存击穿"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11-1 缓存穿透"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "访问一个**不存在的key**，缓存不起作用，请求会穿透到DB，流量大时DB会挂掉"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解决方案** \n",
    "\n",
    "\n",
    "（1）采用**布隆过滤器**，使用一个足够大的bitmap，用于存储可能访问的key，不存在的key直接被过滤；（注意：说完布隆过滤器，就要被问到布隆过滤器的原理了，准备下！）  \n",
    "（2）拦截器，接⼝层增加校验，如给id做校验，id<=0的直接拦截。  \n",
    "（3）从cache和db都取不到，可以将key-value写为key-null，设置较短过期时间，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 【插】布隆过渡器  \n",
    "\n",
    "布隆过滤器是一种占用空间很小的**数据结构**，它由一个很长的**二进制向量**和一组**Hash映射函数**组成的，**不存放数据**   \n",
    "**作用：**用于检索一个元素是否在一个集合中，空间效率和查询时间都比一般的算法要好的多；  \n",
    "**缺点：**有一定的误识别率和删除困难\n",
    "\n",
    "**原理：**通过Hash映射，将一个元素映射到二进制向量中，将该位置**置为1**。那么，如果一个元素通过映射到该二进制向量中，取得的值 为 1 ，那么该元素**可能存在**，反之一定不存在"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11-2 缓存击穿"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个**存在的key**，在缓存**过期的一刻**，同时有大量的请求，这些请求都会击穿到DB，造成瞬时DB请求量大、压力骤增。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解决方案** \n",
    "\n",
    "\n",
    "（1）如果业务情况允许，设置热点数据永远不过期    \n",
    "（2）加互斥锁；在数据为空的时候，设置一个互斥的锁，**只让一个请求**通过，只有一个请求去数据库拉取数据，取完数据，不管如何都需要**释放锁**，异常的时候也需要释放锁，要不其他线程会一直拿不到锁。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**加锁互斥的实现代码**\n",
    "\n",
    "\n",
    "```java\n",
    "\n",
    "static Lock reenLock = new ReentrantLock();\n",
    " \n",
    "    public List<String> getData04() throws InterruptedException {\n",
    "        List<String> result = new ArrayList<String>();\n",
    "        // 从缓存读取数据\n",
    "        result = getDataFromCache();\n",
    "        if (result.isEmpty()) {\n",
    "            if (reenLock.tryLock()) {\n",
    "                try {\n",
    "                    System.out.println(\"我拿到锁了,从DB获取数据库后写入缓存\");\n",
    "                    // 从数据库查询数据\n",
    "                    result = getDataFromDB();\n",
    "                    // 将查询到的数据写入缓存\n",
    "                    setDataToCache(result);\n",
    "                } finally {\n",
    "                    reenLock.unlock();// 释放锁\n",
    "                }\n",
    " \n",
    "            } else {\n",
    "                result = getDataFromCache();// 先查一下缓存\n",
    "                if (result.isEmpty()) {\n",
    "                    System.out.println(\"我没拿到锁,缓存也没数据,先小憩一下\");\n",
    "                    Thread.sleep(100);// 小憩一会儿\n",
    "                    return getData04();// 重试\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        return result;\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11-3 缓存雪崩"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "大量的key设置了**相同的过期时间**，导致在缓存在**同一时刻**全部失效，造成瞬时DB请求量大、压力骤增，引起雪崩。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解决方案**  \n",
    "  主要说前三个就可以啦！    \n",
    "（1）缓存数据的过期时间设置**随机**，防止同一时间大量数据过期现象发生。  \n",
    "（2）如果缓存数据库是分布式部署，将热点数据均匀分布在**不同的缓存数据库**中。  \n",
    "（3）设置热点数据**永远不过期**。  \n",
    "（4）使用**互斥锁**，但是该方案吞吐量明显下降了。  \n",
    "（5）**双缓存**。我们有两个缓存，缓存A和缓存B。缓存A的失效时间为20分钟，缓存B不设失效时间。自己做缓存预热操作。然后细分以下几个小点：  \n",
    "\n",
    "    从缓存A读数据，有则直接返回\n",
    "    A没有数据，直接从B读数据，直接返回，并且异步启动一个更新线程。\n",
    "    更新线程同时更新缓存A和缓存B。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**分级缓存**\n",
    "\n",
    "> 采用 L1 (一级缓存)和 L2(二级缓存) 缓存方式，L1 缓存失效时间短，L2 缓存失效时间长。 请求优先从 L1 缓存获取数据，如果 L1缓存未命中则加锁，只有 1 个线程获取到锁,这个线程再从数据库中读取数据并将数据再更新到到 L1 缓存和 L2 缓存中，而其他线程依旧从 L2 缓存获取数据并返回。\n",
    "\n",
    "这种方式，主要是通过避免缓存同时失效并结合锁机制实现。所以，当数据更 \n",
    "新时，只能淘汰 L1 缓存，不能同时将 L1 和 L2 中的缓存同时淘汰。L2 缓存中 \n",
    "可能会存在脏数据，需要业务能够容忍这种短时间的不一致。而且，这种方案 \n",
    "可能会造成额外的缓存空间浪费"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Redis持久化策略RDB 和 AOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12-1 RDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RDB是一种**快照**存储持久化方式，**周期性**进行持久化\n",
    "\n",
    "具体就是将Redis**某一时刻**的内存数据保存到硬盘的文件当中，默认保存的文件名为**dump.rdb**，而在Redis服务器启动时，会重新加载dump.rdb文件的数据到内存当中恢复数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "开启Redis RDB持久化：\n",
    "\n",
    "* 客户端向Redis发送**save**或**bgsave**命令让服务器生成rdb文件\n",
    "* 配置Redis配置文件，触发执行条件时自动备份\n",
    "\n",
    "P.S. 如果数据量太大，同步数据会执行很久，而这期间Redis服务器也无法接收其他请求，所以，最好不要在生产环境使用save命令。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 客户端发送命令启动持久化\n",
    "**save和bgsave**  \n",
    "\n",
    "* save是一个同步操作，是阻塞的\n",
    "* bgsave是一个异步操作，是通过redis开辟的一个子进程来进行数据同步，在数据同步完成后，子进程会自动退出\n",
    "* save命令执行持久化时，服务器会阻塞save命令以后的其他客户端请求\n",
    "* bgsave命令执行持久化时，服务器的主进程仍可以接收其他请求，但是子进程依然是同步的；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 触发RDB持久化的条件——使用子进程同步数据\n",
    "\n",
    "比如【多少秒内至少达到多少写操作】\n",
    "\n",
    "\\# 900s内至少达到一条写命令  \n",
    "save 900 1  \n",
    "\\# 300s内至少达至10条写命令  \n",
    "save 300 10  \n",
    "\\# 60s内至少达到10000条写命令  \n",
    "save 60 10000  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### rdb文件的生成——主进程/子进程\n",
    "\n",
    "1. 生成临时rdb文件，并写入数据。\n",
    "2. 完成数据写入，用临时文代替代正式rdb文件。\n",
    "3. 删除原来的db文件。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RDB的几个优点\n",
    "\n",
    "1. 与AOF方式相比，通过rdb文件**恢复数据比较快**。\n",
    "2. rdb文件非常紧凑，适合于数据备份。\n",
    "3. 通过RDB进行数据备，由于使用子进程生成，所以对Redis服务器性能**影响较小**。\n",
    "\n",
    "### RDB的几个缺点\n",
    "\n",
    "1. 如果服务器宕机的话，采用RDB的方式会造成**某个时段**内数据的丢失，比如我们设置10分钟同步一次或5分钟达到1000次写入就同步一次，那么如果还没达到触发条件服务器就死机了，那么这个时间段的数据会丢失。\n",
    "2. 使用save命令会造成服务器**阻塞**，直接数据同步完成才能接收后续请求。\n",
    "3. 使用bgsave命令在forks子进程时，如果数据量太大，forks的过程也会发生阻塞，另外，forks子进程会耗费内存。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12-2AOF (Append-only file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AOF持久化方式会记录客户端对服务器的每一次**写操作**命令，并将这些写操作以Redis协议追加保存到以后缀为aof文件末尾，在Redis服务器重启时，会加载并运行aof文件的命令，以达到恢复数据的目的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Redis默认是不开启AOF持久化策略的，可以通过修改配置文件开启\n",
    "* 使用子进程进行 **写操作**的命令追加"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 三种写入策略  \n",
    "* appendfsync always\n",
    "* appendfsync everysec\n",
    "* appendfsync no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**always**  \n",
    "\n",
    "客户端的每一个写操作都保存到aof文件当，这种策略很安全，但是每个写请注都有IO操作，所以也很慢    \n",
    "\n",
    "**everysec**     \n",
    "\n",
    "默认写入策略，每秒写入一次aof文件，因此，最多可能会丢失1s的数据  \n",
    "\n",
    "**no**    \n",
    "\n",
    "Redis服务器不负责写入aof，而是交由操作系统来处理什么时候写入aof文件。更快，但也是最不安全的选择，不推荐使用。  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为使用AOF策略，Redis会将每一个写操作都记入到aof文件中，如果一个key执行多次操作时，其实中间的一些操作可以不记录，仅记录最后一个即可，否则aof的文件会变的非常大。\n",
    "\n",
    "因此可以对aof进行重写。\n",
    "\n",
    "incr num 1  \n",
    "incr num 2  \n",
    "incr num 3  \n",
    "\n",
    "->\n",
    "set num 3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**重写的2种方式**\n",
    "1. 服务端通过配置文件设置（no-appendfsync-on-rewrite yes），但是这种方式会在每次同步的时候都重写，影响性能，默认不no\n",
    "\n",
    "2. 客户端通过发送bgrewriteaof命令，让服务端重写aof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 重写aof文件的好处\n",
    "1. 压缩aof文件，减少磁盘占用量。\n",
    "\n",
    "2. 将aof的命令压缩为最小命令集，加快了数据恢复的速度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AOF的优点\n",
    "* AOF只是追加日志文件，因此对服务器性能影响较小，速度比RDB要快，消耗的内存较少。\n",
    "\n",
    "### AOF的缺点\n",
    "* AOF方式生成的日志文件太大，即使通过AFO重写，文件体积仍然很大。\n",
    "\n",
    "* 恢复数据的速度比RDB慢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以RDB, AOF两种备份一起用，出问题的时候第一时间用RDB恢复，然后AOF做数据补全"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/redis-bg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Redis过期键的删除策略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Redis有三种过期删除策略：定时删除， 惰性删除， 定期删除**  \n",
    "\n",
    "**① 定时删除**  \n",
    "　　在设置某个key 的过期时间同时，我们创建一个定时器，让定时器在该过期时间到来时，立即执行对其进行删除的操作。  \n",
    "\n",
    "* 优点：定时删除对内存是最友好的，能够保存内存的key一旦过期就能立即从内存中删除。  \n",
    "\n",
    "* 缺点：对CPU最不友好，在过期键比较多的时候，删除过期键会占用一部分 CPU 时间，对服务器的响应时间和吞吐量造成影响。 \n",
    "\n",
    "**② 惰性删除**  \n",
    "　　设置该key 过期时间后，我们不去管它，当需要该key时，我们在检查其是否过期，如果过期，我们就删掉它，反之返回该key。\n",
    "\n",
    "* 优点：对 CPU友好，我们只会在使用该键时才会进行过期检查，对于很多用不到的key不用浪费时间进行过期检查。\n",
    "\n",
    "* 缺点：对内存不友好，如果一个键已经过期，但是一直没有使用，那么该键就会一直存在内存中，如果数据库中有很多这种使用不到的过期键，这些键便永远不会被删除，内存永远不会释放。从而造成内存泄漏。\n",
    "\n",
    "**③ 定期删除**  \n",
    "　　每隔一段时间，我们就**随机**对一些key进行检查，删除里面过期的key。（\n",
    "  为什么不是全部扫描：全部扫描浪费时间，效率不高）\n",
    "\n",
    "* 优点：可以通过限制删除操作执行的时长和频率来减少删除操作对 CPU 的影响。另外定期删除，也能有效释放过期键占用的内存。\n",
    "\n",
    "* 缺点：难以确定删除操作执行的时长和频率。  \n",
    "    如果执行的太频繁，定期删除策略变得和定时删除策略一样，对CPU不友好。  \n",
    "    如果执行的太少，那又和惰性删除一样了，过期键占用的内存不会及时得到释放。  \n",
    "\n",
    "\n",
    "\n",
    "* 另外最重要的是，在获取某个键时，如果某个键的过期时间已经到了，但是还没执行定期删除，那么就会返回这个键的值，这是业务不能忍受的错误。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redis默认采用的过期删除策略是：**定期删除**+**惰性删除**两种"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 惰性删除策略的实现\n",
    "惰性删除策略由 **expireIfNeeded 函数**实现，所有读写数据库的 Redis 命令在执行之前都会调用 **exipreIfNeeded 函数**对输入键进行检查。\n",
    "\n",
    "* 如果键过期，会将键删除并返回空。\n",
    "* 如果键没有过期，则不做操作。\n",
    "\n",
    "### 定期删除策略的实现\n",
    "定期删除策略由 **activeExpireCycle 函数**实现，被调用时，它在规定的时间内，分**多次**遍历服务器中的**各个数据库**，从数据库的 expires 字典中随机检查一部分键的过期时间，并删除其中的过期键。\n",
    "\n",
    "* 函数每次运行时，都是从一定数量的数据库键中随机取一定数量的键进行检查，并删除其中的过期键。\n",
    "有一个全局变量 current_db 会记录当前 activeExpireCycle 函数检查的进度，并且下一次 函数执行时，**接着上一次**的进度进行处理。如，当前 activeExpireCycle 函数执行到了 10， 讲 current_db = 10；然后下一次函数执行时，从 current_db 取到 10 继续执行。\n",
    "* 当所有的数据库键都被检查完时， current_db = 0。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 如果定期没删，也没查询，怎么办？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**内存淘汰机制！8个**\n",
    "\n",
    "当触发内存不足的时候才会触发以上策略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* volatile-lru：尝试回收 最少使用的键(LRU)，仅限于过期集合的键。\n",
    "* allkeys-lru：在所有的数据中淘汰最少使用的数据。\n",
    "* volatile-lfu：在设置过期时间的数据中淘汰使用频率最低的数据。\n",
    "* allkeys-lfu：在所有的数据中淘汰使用使用频率最低的数据。\n",
    "* volatile-random：在设置过期时间的数据中淘汰任意随机数据。\n",
    "* allkeys-random：在所有的数据中随机淘汰数据。\n",
    "* volatile-ttl：在设置过期时间的数据中淘汰最早过期的数据。\n",
    "* no-eviction：默认策略，不淘汰数据，新增或者修改数据会抛异常，但是读操作正常进行，不受影响（一般不用）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 过期键与RDB, AOF持久化策略"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RDB\n",
    "1. 在生成RDB文件时，已过期的键不会被保存到新的RDB文件中，即过期键不会对新的 RDB 文件造成影响\n",
    "2. 在载入RDB文件时  \n",
    "    * 如果服务器以**主服务器**模式运行，那么在载入 RDB 文件时，过期的键会被过滤掉，不会被载入到redis数据库中。\n",
    "    * 如果以**从服务器**模式运行，那么无论键是否过期都会被载入到数据库中。但，因为主从服务器在进行数据同步时，从服务器就会被清空，所以，一般来说，过期键对从服务器也不会造成影响。\n",
    "\n",
    "#### AOF\n",
    "1. 当服务器开启 AOF 的运行模式时，如果某个键**过期**了，但**没有**被惰性或定期删除，那么 AOF 不会理会。如果被惰性或定期**删除**了， AOF 会在文件末尾追加一条**DEL**命令，来显示地记录该键已被删除。\n",
    "2. 当 AOF **重写**时，过期的键不会被载入到 redis 数据库中\n",
    "3. 服务器在 复制 模式下时，从服务器的过期键删除动作都是由主服务器来进行的。  \n",
    "    * 主服务器在删除一个过期键之后，会显示地向所有从服务器发送一个 DEL 命令，告知从服务器删除这个过期键。\n",
    "    * 从服务器在执行客户端发送的读命令时，即使碰到过期的键也不会删除，而是继续的正常操作。\n",
    "    * 从服务器只有在接到主服务器发来的 DEL 命令之后，才会删除过期键。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 既然从服务器不会主动去删除过期键，那么如果查询从服务器的过期键怎么办？\n",
    "\n",
    "* 从服务器会使用一个 **逻辑时钟**来报告一个键不存在\n",
    "* 从服务器使用它的**逻辑时钟**以报告只有在**不违反数据集的一致性**的读取操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Redis与MySQL一致性如何保证？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先更新数据库，再删除缓存"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Redis 如何实现消息队列的？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **使用Redis的list**，通过lpush, rpush, lpop, rpop, brpop等对数据进行存、取；\n",
    "\n",
    "\n",
    "* list列表中的数据本来就是FIFO的；"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **使用Redis的发布订阅**\n",
    "\n",
    "\n",
    "由于Redis发布订阅的消息是不进行持久化的，所以这种方式更适合实时通信；但是该方法支持**广播**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **使用Zset**:同list，但是不能设置重复的key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. 主从复制"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "主服务器写，从服务器读"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**数据一致性问题**：  \n",
    "主从库是同步数据方式有两种：\n",
    "\n",
    "* **全量同步**：通常是主从服务器刚刚连接的时候，会先进行全量同步\n",
    "* **增量同步** ：一般在全同步结束后，进行增量同步，比如主从库间网络断，再进行数据同步。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://juejin.cn/post/6920457759393742862#heading-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**全量同步**：\n",
    "1. 从库向主库发送$psync$，请求同步数据，同时会把offset和runID一同发送给主库，一开始，不知道offset的值，offset为-1，runID为主库的随机标识码\n",
    "2. 主库接受到从库的请求，将RDB文件发送给从库，从库收到数据后，会先清空当前数据库，然后加载从主库获取的RDB 文件\n",
    "3. 主库完成 RDB 文件发送后，也会把将保存发送RDB文件期间写操作的replication buffer发给从库，从库再重新执行这些操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/redis-ms.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**增量同步**：基于环形缓冲区*repl_backlog_buffer*缓存区实现\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 在环形缓冲区，主库会记录自己写到的位置 *master_repl_offset* ，从库则会记录自己已经读到的位置*slave_repl_offset*, 主库并通过*master_repl_offset* 和 *slave_repl_offset*的差值的数据同步到从库\n",
    "* 异常情况恢复也是通过增量同步完成\n",
    "* 如果从库读取太慢，有可能主库写的太快，导致主库的指针快从库一圈，导致数据不一致\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. 哨兵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般是奇数，通过投票进行选举新的主库"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
